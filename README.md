# Knowledge Diffusion for Distillation (DiffKD)
Official implementation for paper "[Knowledge Diffusion for Distillation](https://arxiv.org/abs/2305.15712)" (DiffKD).

We are busy in other projects, the code will be released soon.

---

## Updates
### June 9, 2023
We released the core code of DiffKD. See `example.py` for usage.